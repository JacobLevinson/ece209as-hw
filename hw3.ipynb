{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import random\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi :)\n"
     ]
    }
   ],
   "source": [
    "print(\"hi :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import random\n",
    "import time\n",
    "\n",
    "# load a file and return its lines as a list\n",
    "def load_memory_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "    return lines\n",
    "\n",
    "# Load files (adjust the file paths as needed)\n",
    "random_memory = load_memory_file('random_numbers_16.txt')\n",
    "zeros_memory = load_memory_file('zeros_8.txt')\n",
    "attack_memory = load_memory_file('attack_8.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prover(nonce, memory_lines):\n",
    "    # Initialize with the nonce as a starting value (convert to string)\n",
    "    prev_hash = hashlib.sha256(str(nonce).encode()).hexdigest()\n",
    "    for line in memory_lines:\n",
    "        # Concatenate previous hash and the current line, then update the hash.\n",
    "        combined = prev_hash + line\n",
    "        prev_hash = hashlib.sha256(combined.encode()).hexdigest()\n",
    "    return prev_hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attestation passed: True, Time: 0.002245 sec\n"
     ]
    }
   ],
   "source": [
    "used_nonces = set() # I guess this is one way to do it...\n",
    "\n",
    "def generate_nonce():\n",
    "    nonce = random.randint(0, 256)\n",
    "    while nonce in used_nonces:\n",
    "        nonce = random.randint(0, 256)\n",
    "    used_nonces.add(nonce)\n",
    "    return nonce\n",
    "\n",
    "def verifier(prover_function, memory_lines):\n",
    "    nonce = generate_nonce()\n",
    "    # Start timer\n",
    "    start_time = time.perf_counter()\n",
    "    # Get hash from prover\n",
    "    prover_hash = prover_function(nonce, memory_lines)\n",
    "    # Compute expected hash locally using the same algorithm\n",
    "    expected_hash = prover(nonce, memory_lines)\n",
    "    # End timer\n",
    "    end_time = time.perf_counter()\n",
    "    attestation_time = end_time - start_time\n",
    "    # Check if the attestation passes\n",
    "    passed = (prover_hash == expected_hash)\n",
    "    return passed, attestation_time, nonce, expected_hash, prover_hash\n",
    "\n",
    "# Example run:\n",
    "passed, att_time, nonce, exp_hash, prov_hash = verifier(prover, random_memory)\n",
    "print(f\"Attestation passed: {passed}, Time: {att_time:.6f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual attestation times: [0.0011598250002862187, 0.0012267310003153398, 0.0011961749996771687, 0.0013689380002688267, 0.0011684199998853728, 0.0012333539998508058, 0.0012662489998547244, 0.0014393800001926138, 0.0012367210001684725, 0.001320067999586172]\n",
      "Average attestation time: 0.001262 sec\n"
     ]
    }
   ],
   "source": [
    "def performance_analysis(prover_function, memory_lines, runs=10):\n",
    "    times = []\n",
    "    for i in range(runs):\n",
    "        _, att_time, _, _, _ = verifier(prover_function, memory_lines)\n",
    "        times.append(att_time)\n",
    "    average_time = sum(times) / len(times)\n",
    "    return times, average_time\n",
    "\n",
    "times, avg_time = performance_analysis(prover, random_memory)\n",
    "print(\"Individual attestation times:\", times)\n",
    "print(f\"Average attestation time: {avg_time:.6f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_attack_data(zeros_lines, attack_lines):\n",
    "    # Replace zero values in attack_lines with corresponding non-zero values from zeros_lines\n",
    "    modified_attack = []\n",
    "    for zero, attack in zip(zeros_lines, attack_lines):\n",
    "        # Replace if the attack entry is zero (as a string or numeric zero)\n",
    "        if attack == \"0\" or attack == 0:\n",
    "            modified_attack.append(zero)\n",
    "        else:\n",
    "            modified_attack.append(attack)\n",
    "    return modified_attack\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious prover times: [0.0012147340003139107, 0.0011638659998425283, 0.001135534000241023, 0.0014322340002763667, 0.001186194999718282, 0.001174449999780336, 0.0012257500002306188, 0.0013164049996703397, 0.0012974520004718215, 0.0014192309999998542]\n",
      "Average malicious attestation time: 0.001257 sec\n"
     ]
    }
   ],
   "source": [
    "def malicious_prover(nonce, attack_memory_lines, zeros_memory_lines):\n",
    "    # Compute the modified data by replacing zeros in attack data with non-zero values from zeros_memory_lines.\n",
    "    modified_data = precompute_attack_data(zeros_memory_lines, attack_memory_lines)\n",
    "    # Compute the cumulative SHA-256 hash (using the same algorithm as the legitimate prover)\n",
    "    return prover(nonce, modified_data)\n",
    "\n",
    "# Create a wrapper that only takes two arguments\n",
    "malicious_wrapper = lambda nonce, memory_lines: malicious_prover(nonce, memory_lines, zeros_memory)\n",
    "\n",
    "# Measure malicious prover performance over 10 runs using the wrapper.\n",
    "malicious_times, malicious_avg = performance_analysis(malicious_wrapper, attack_memory)\n",
    "print(\"Malicious prover times:\", malicious_times)\n",
    "print(f\"Average malicious attestation time: {malicious_avg:.6f} sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legitimate times: [0.001112602999455703, 0.0011190200002602069, 0.0011821629996120464, 0.0018902390002040192, 0.0011743319992092438, 0.001137496000410465, 0.0011754500001188717, 0.0011707399999068002, 0.00112522900053591, 0.0011082730006819475, 0.0011043670001527062, 0.0012275499993847916, 0.0013976829995954176, 0.0012048790003973409, 0.001129045000197948, 0.001231573000040953, 0.0013126070007274393, 0.0011577999994187849, 0.001214130999869667, 0.001124148999224417, 0.001319465000051423, 0.001139279000199167, 0.0011170750003657304, 0.0011249870003666729, 0.0013128139999025734, 0.0011237629996685428, 0.0011109469996881671, 0.0012738900004478637, 0.0011081470001954585, 0.0011769520006055245, 0.0010940630008917651, 0.0010832549996848684, 0.0010776749995784485, 0.0011481790006655501, 0.001136020999183529, 0.0010789069992824807, 0.0010848560004887986, 0.0011118379998151795, 0.0013523690004149103, 0.0011100639994765515, 0.0010932620007224614, 0.0010781419996419572, 0.0011765279996325262, 0.0011019459998351522, 0.0011194970002179616, 0.0011184439999851747, 0.001174701999843819, 0.0011362459999872954, 0.001098679999813612, 0.0011267419995419914]\n",
      "Malicious times: [0.0011368659997970099, 0.00152294500003336, 0.0012043659999108058, 0.0011626870000327472, 0.001392731999658281, 0.001306334000219067, 0.0011847460000353749, 0.0011323400003675488, 0.0011788689998866175, 0.001218134999362519, 0.0011629219998212648, 0.0011515630003486876, 0.0011582500001168228, 0.0011653510000542155, 0.0011780949998865253, 0.0011612739999691257, 0.0012247790000401437, 0.0011693019996528164, 0.0011727230003089062, 0.001162706000286562, 0.0011626239993347554, 0.0011695900002450799, 0.001180147000013676, 0.0011500059999889345, 0.001157394999609096, 0.0011511499997141073, 0.0011504289996082662, 0.001171623999653093, 0.0011506549999467097, 0.0011430500007918454, 0.0011707869998645037, 0.0011648380004771752, 0.0011715959999492043, 0.0011560630000531091, 0.0011581689996091882, 0.001155891999587766, 0.0011619220003922237, 0.001162560000011581, 0.001156008999714686, 0.0011924850005016197, 0.001157450000391691, 0.0011643699999694945, 0.0011527599999681115, 0.0011497360001158086, 0.0011712200002875761, 0.001155955999820435, 0.0011604009996517561, 0.001177393000034499, 0.0011815600000772974, 0.0011634790007519769]\n",
      "Response time threshold: 0.001176 sec\n"
     ]
    }
   ],
   "source": [
    "def collect_times(prover_function, memory_lines, runs=50):\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        _, att_time, _, _, _ = verifier(prover_function, memory_lines)\n",
    "        times.append(att_time)\n",
    "    return times\n",
    "\n",
    "legit_times = collect_times(prover, random_memory)\n",
    "malicious_times = collect_times(malicious_wrapper, attack_memory)\n",
    "\n",
    "print(\"Legitimate times:\", legit_times)\n",
    "print(\"Malicious times:\", malicious_times)\n",
    "\n",
    "# Set the threshold as a value between the average legitimate and malicious times.\n",
    "threshold = (sum(legit_times)/len(legit_times) + sum(malicious_times)/len(malicious_times)) / 2\n",
    "print(f\"Response time threshold: {threshold:.6f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate: 96.00%\n",
      "False Positive Rate: 0.00%\n"
     ]
    }
   ],
   "source": [
    "def enhanced_verifier(prover_function, memory_lines, time_threshold):\n",
    "    nonce = generate_nonce()\n",
    "    start_time = time.perf_counter()\n",
    "    prover_hash = prover_function(nonce, memory_lines)\n",
    "    end_time = time.perf_counter()\n",
    "    attestation_time = end_time - start_time\n",
    "\n",
    "    expected_hash = prover(nonce, memory_lines)\n",
    "    passed_hash = (prover_hash == expected_hash)\n",
    "    # Check timing as an additional defense.\n",
    "    passed_time = (attestation_time <= time_threshold)\n",
    "    overall_passed = passed_hash and passed_time\n",
    "    return overall_passed, attestation_time, passed_hash, passed_time\n",
    "\n",
    "# Conduct 100 runs (50 of each) to calculate TPR and FPR.\n",
    "def threshold_detection_analysis(time_threshold):\n",
    "    legitimate_results = [enhanced_verifier(prover, random_memory, time_threshold)[0] for _ in range(50)]\n",
    "    malicious_results = [enhanced_verifier(malicious_wrapper, attack_memory, time_threshold)[0] for _ in range(50)]\n",
    "    \n",
    "    # True Positive Rate (TPR): legitimate responses accepted.\n",
    "    TPR = sum(legitimate_results) / len(legitimate_results)\n",
    "    # False Positive Rate (FPR): malicious responses mistakenly accepted.\n",
    "    FPR = sum(malicious_results) / len(malicious_results)\n",
    "    return TPR, FPR\n",
    "\n",
    "TPR, FPR = threshold_detection_analysis(threshold)\n",
    "print(f\"True Positive Rate: {TPR*100:.2f}%\")\n",
    "print(f\"False Positive Rate: {FPR*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Noise Simulation Analysis for Both Legitimate and Malicious Provers ---\n",
      "Noise STD: 0.000100 sec, TPR: 100.00%, FPR: 0.00%\n",
      "Noise STD: 0.000110 sec, TPR: 99.50%, FPR: 0.00%\n",
      "Noise STD: 0.000120 sec, TPR: 100.00%, FPR: 0.00%\n",
      "Noise STD: 0.000130 sec, TPR: 100.00%, FPR: 0.00%\n",
      "Noise STD: 0.000140 sec, TPR: 99.00%, FPR: 0.00%\n",
      "Noise STD: 0.000150 sec, TPR: 99.00%, FPR: 0.00%\n",
      "Noise STD: 0.000160 sec, TPR: 99.50%, FPR: 0.00%\n",
      "Noise STD: 0.000170 sec, TPR: 100.00%, FPR: 0.00%\n",
      "Noise STD: 0.000180 sec, TPR: 98.50%, FPR: 0.00%\n",
      "Noise STD: 0.000190 sec, TPR: 99.50%, FPR: 0.00%\n",
      "Noise STD: 0.000200 sec, TPR: 99.00%, FPR: 0.00%\n",
      "Noise STD: 0.000210 sec, TPR: 97.50%, FPR: 0.00%\n",
      "Noise STD: 0.000220 sec, TPR: 99.50%, FPR: 0.00%\n",
      "Noise STD: 0.000230 sec, TPR: 99.00%, FPR: 0.00%\n",
      "Noise STD: 0.000240 sec, TPR: 98.00%, FPR: 0.00%\n",
      "Noise STD: 0.000250 sec, TPR: 98.00%, FPR: 0.00%\n",
      "Noise STD: 0.000260 sec, TPR: 97.50%, FPR: 0.00%\n",
      "Noise STD: 0.000270 sec, TPR: 95.50%, FPR: 0.00%\n",
      "Noise STD: 0.000280 sec, TPR: 98.50%, FPR: 0.00%\n",
      "Noise STD: 0.000290 sec, TPR: 94.00%, FPR: 0.00%\n",
      "Noise STD: 0.000300 sec, TPR: 95.00%, FPR: 0.00%\n",
      "Noise STD: 0.000310 sec, TPR: 93.50%, FPR: 0.00%\n",
      "Noise STD: 0.000320 sec, TPR: 92.50%, FPR: 0.00%\n",
      "Noise STD: 0.000330 sec, TPR: 91.50%, FPR: 0.00%\n",
      "Noise STD: 0.000340 sec, TPR: 88.50%, FPR: 0.00%\n",
      "Noise STD: 0.000350 sec, TPR: 88.00%, FPR: 0.00%\n",
      "Noise STD: 0.000360 sec, TPR: 89.50%, FPR: 0.00%\n",
      "Noise STD: 0.000370 sec, TPR: 85.50%, FPR: 0.00%\n",
      "Noise STD: 0.000380 sec, TPR: 86.00%, FPR: 0.00%\n",
      "Noise STD: 0.000390 sec, TPR: 84.00%, FPR: 0.00%\n",
      "Noise STD: 0.000400 sec, TPR: 83.50%, FPR: 0.00%\n",
      "Noise STD: 0.000410 sec, TPR: 78.00%, FPR: 0.00%\n",
      "Noise STD: 0.000420 sec, TPR: 81.50%, FPR: 0.00%\n",
      "Noise STD: 0.000430 sec, TPR: 85.00%, FPR: 0.00%\n",
      "Noise STD: 0.000440 sec, TPR: 78.00%, FPR: 0.00%\n",
      "Noise STD: 0.000450 sec, TPR: 72.50%, FPR: 0.00%\n",
      "Noise STD: 0.000460 sec, TPR: 80.00%, FPR: 0.00%\n",
      "Noise STD: 0.000470 sec, TPR: 70.50%, FPR: 0.00%\n",
      "Noise STD: 0.000480 sec, TPR: 74.50%, FPR: 0.00%\n",
      "Noise STD: 0.000490 sec, TPR: 70.50%, FPR: 0.00%\n",
      "Noise STD: 0.000500 sec, TPR: 74.00%, FPR: 0.00%\n",
      "Noise STD: 0.000510 sec, TPR: 72.00%, FPR: 0.00%\n",
      "Noise STD: 0.000520 sec, TPR: 78.50%, FPR: 0.00%\n",
      "Noise STD: 0.000530 sec, TPR: 75.00%, FPR: 0.00%\n",
      "Noise STD: 0.000540 sec, TPR: 78.50%, FPR: 0.00%\n",
      "Noise STD: 0.000550 sec, TPR: 70.50%, FPR: 0.00%\n",
      "Noise STD: 0.000560 sec, TPR: 71.00%, FPR: 0.00%\n",
      "Noise STD: 0.000570 sec, TPR: 75.00%, FPR: 0.00%\n",
      "Noise STD: 0.000580 sec, TPR: 72.00%, FPR: 0.00%\n",
      "Noise STD: 0.000590 sec, TPR: 67.00%, FPR: 0.00%\n",
      "Noise STD: 0.000600 sec, TPR: 65.50%, FPR: 0.00%\n",
      "Noise STD: 0.000610 sec, TPR: 63.00%, FPR: 0.00%\n",
      "Noise STD: 0.000620 sec, TPR: 65.50%, FPR: 0.00%\n",
      "Noise STD: 0.000630 sec, TPR: 61.50%, FPR: 0.00%\n",
      "Noise STD: 0.000640 sec, TPR: 59.50%, FPR: 0.00%\n",
      "Noise STD: 0.000650 sec, TPR: 65.00%, FPR: 0.00%\n",
      "Noise STD: 0.000660 sec, TPR: 62.00%, FPR: 0.00%\n",
      "Noise STD: 0.000670 sec, TPR: 61.00%, FPR: 0.00%\n",
      "Noise STD: 0.000680 sec, TPR: 57.50%, FPR: 0.00%\n",
      "Noise STD: 0.000690 sec, TPR: 68.50%, FPR: 0.00%\n",
      "Noise STD: 0.000700 sec, TPR: 60.00%, FPR: 0.00%\n",
      "Noise STD: 0.000710 sec, TPR: 60.00%, FPR: 0.00%\n",
      "Noise STD: 0.000720 sec, TPR: 52.50%, FPR: 0.00%\n",
      "Noise STD: 0.000730 sec, TPR: 49.00%, FPR: 0.00%\n",
      "Noise STD: 0.000740 sec, TPR: 57.50%, FPR: 0.00%\n",
      "Noise STD: 0.000750 sec, TPR: 55.50%, FPR: 0.00%\n",
      "Noise STD: 0.000760 sec, TPR: 55.50%, FPR: 0.00%\n",
      "Noise STD: 0.000770 sec, TPR: 49.00%, FPR: 0.00%\n",
      "Noise STD: 0.000780 sec, TPR: 56.50%, FPR: 0.00%\n",
      "Noise STD: 0.000790 sec, TPR: 56.00%, FPR: 0.00%\n",
      "Noise STD: 0.000800 sec, TPR: 48.00%, FPR: 0.00%\n",
      "Noise STD: 0.000810 sec, TPR: 55.50%, FPR: 0.00%\n",
      "Noise STD: 0.000820 sec, TPR: 56.50%, FPR: 0.00%\n",
      "Noise STD: 0.000830 sec, TPR: 46.00%, FPR: 0.00%\n",
      "Noise STD: 0.000840 sec, TPR: 52.50%, FPR: 0.00%\n",
      "Noise STD: 0.000850 sec, TPR: 50.50%, FPR: 0.00%\n",
      "Noise STD: 0.000860 sec, TPR: 53.00%, FPR: 0.00%\n",
      "Noise STD: 0.000870 sec, TPR: 51.00%, FPR: 0.00%\n",
      "Noise STD: 0.000880 sec, TPR: 43.50%, FPR: 0.00%\n",
      "Noise STD: 0.000890 sec, TPR: 50.00%, FPR: 0.00%\n",
      "Noise STD: 0.000900 sec, TPR: 42.50%, FPR: 0.00%\n",
      "Noise STD: 0.000910 sec, TPR: 49.00%, FPR: 0.00%\n",
      "Noise STD: 0.000920 sec, TPR: 50.00%, FPR: 0.00%\n",
      "Noise STD: 0.000930 sec, TPR: 50.00%, FPR: 0.00%\n",
      "Noise STD: 0.000940 sec, TPR: 40.50%, FPR: 0.00%\n",
      "Noise STD: 0.000950 sec, TPR: 44.00%, FPR: 0.00%\n",
      "Noise STD: 0.000960 sec, TPR: 47.00%, FPR: 0.00%\n",
      "Noise STD: 0.000970 sec, TPR: 45.50%, FPR: 0.00%\n",
      "Noise STD: 0.000980 sec, TPR: 40.50%, FPR: 0.00%\n",
      "Noise STD: 0.000990 sec, TPR: 41.00%, FPR: 0.00%\n",
      "\n",
      "TPR is around 50% for noise standard deviation ≈ 0.000720 sec\n"
     ]
    }
   ],
   "source": [
    "def reset_nonces():\n",
    "    global used_nonces\n",
    "    used_nonces = set()\n",
    "\n",
    "def simulate_noise(noise_std):\n",
    "    \"\"\"\n",
    "    Simulate noise as a random delay from a normal distribution with mean 0 and standard deviation noise_std.\n",
    "    Use the absolute value so the noise delay is always positive.\n",
    "    \"\"\"\n",
    "    noise = abs(random.gauss(0, noise_std))\n",
    "    return noise\n",
    "\n",
    "def enhanced_verifier_with_noise(prover_function, memory_lines, time_threshold, noise_std):\n",
    "    \"\"\"\n",
    "    Enhanced verifier that includes noise in the attestation time measurement.\n",
    "    noise_std: standard deviation of the noise delay (in seconds).\n",
    "    \"\"\"\n",
    "    nonce = generate_nonce()\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # Introduce simulated noise (network/computation delay)\n",
    "    noise_delay = simulate_noise(noise_std)\n",
    "    time.sleep(noise_delay)\n",
    "    \n",
    "    # Get the prover's response after the noise delay.\n",
    "    prover_hash = prover_function(nonce, memory_lines)\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    attestation_time = end_time - start_time\n",
    "    expected_hash = prover(nonce, memory_lines)\n",
    "    passed_hash = (prover_hash == expected_hash)\n",
    "    passed_time = (attestation_time <= time_threshold)\n",
    "    overall_passed = passed_hash and passed_time\n",
    "    return overall_passed, attestation_time, passed_hash, passed_time\n",
    "\n",
    "def noise_simulation_analysis(time_threshold, noise_std_values, runs=100):\n",
    "    results = []\n",
    "    for noise_std in noise_std_values:\n",
    "        reset_nonces()  # Reset nonces for each noise level test\n",
    "        legitimate_outcomes = [enhanced_verifier_with_noise(prover, random_memory, time_threshold, noise_std)[0]\n",
    "                               for _ in range(runs)]\n",
    "        reset_nonces()  # Reset nonces again for the malicious tests\n",
    "        malicious_outcomes = [enhanced_verifier_with_noise(malicious_wrapper, attack_memory, time_threshold, noise_std)[0]\n",
    "                              for _ in range(runs)]\n",
    "        TPR = sum(legitimate_outcomes) / len(legitimate_outcomes)\n",
    "        FPR = sum(malicious_outcomes) / len(malicious_outcomes)\n",
    "        results.append((noise_std, TPR, FPR))\n",
    "        print(f\"Noise STD: {noise_std:.6f} sec, TPR: {TPR*100:.2f}%, FPR: {FPR*100:.2f}%\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# From 0.0005 sec to 0.001 sec with increments of 0.00005 sec.\n",
    "noise_std_values = np.arange(0.0001, 0.00100, 0.00001).tolist()\n",
    "\n",
    "print(\"\\n--- Noise Simulation Analysis for Both Legitimate and Malicious Provers ---\")\n",
    "noise_results = noise_simulation_analysis(threshold, noise_std_values, runs=200)\n",
    "\n",
    "# Find the approximate noise level where TPR falls to ~50%\n",
    "for noise_std, tpr, fpr in noise_results:\n",
    "    if abs(tpr - 0.5) < 0.05:  # within 5% of 50%\n",
    "        print(f\"\\nTPR is around 50% for noise standard deviation ≈ {noise_std:.6f} sec\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techniques to Improve Attestation Accuracy Despite Noise\n",
    "\n",
    "- **Statistical Filtering:**  \n",
    "  - Use multiple measurements of the attestation time and compute statistics (like the mean or median) to reduce the impact of random fluctuations.  \n",
    "  - Filtering out outliers helps smooth the results and better estimate the true response time.\n",
    "\n",
    "- **Adaptive Thresholds:**  \n",
    "  - Instead of a fixed time threshold, adjust the threshold based on observed noise levels and historical performance.  \n",
    "  - This dynamic approach allows the system to account for varying network and processing conditions, reducing false positives and negatives.\n",
    "\n",
    "- **Multiple Verification Attempts:**  \n",
    "  - Perform several attestation checks consecutively rather than relying on a single measurement.  \n",
    "  - By requiring multiple successful verifications (or averaging the results), transient noise effects can be minimized, leading to a more robust verification process.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece209as",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
